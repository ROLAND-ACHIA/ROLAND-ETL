{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ INTEGRATED ETL PIPELINE: CDSE + WEkEO\n",
      "======================================================================\n",
      "üîë Authenticating with CDSE...\n",
      "‚úÖ CDSE authentication successful\n",
      "üîë Authenticating with WEkEO...\n",
      "‚úÖ WEkEO authentication successful\n",
      "\n",
      "======================================================================\n",
      "üì• EXTRACT PHASE\n",
      "======================================================================\n",
      "\n",
      "üì¶ EXTRACT: Loading AOI shapefile...\n",
      "‚úÖ AOI loaded: Douala1_aoi.shp\n",
      "   Bounding box: [9.6500857 4.0024729 9.7269546 4.0975471]\n",
      "\n",
      "üõ∞Ô∏è EXTRACT: Sentinel-2 from CDSE...\n",
      "‚úÖ Found: S2B_MSIL2A_20240101T093319_N0510_R136_T32NNK_20240101T121324.SAFE\n",
      "‚úÖ Product already downloaded\n",
      "\n",
      "üå°Ô∏è EXTRACT: Temperature data from WEkEO...\n",
      "‚ö†Ô∏è Temperature extraction failed: 404 Client Error: Not Found for url: https://gateway.prod.wekeo2.eu/hda-broker/api/v1/dataaccess/jobs\n",
      "\n",
      "======================================================================\n",
      "üîÑ TRANSFORM PHASE\n",
      "======================================================================\n",
      "\n",
      "üîÑ TRANSFORM: Computing Sentinel-2 indices...\n",
      "   Resampling B5 from (527, 427) to (1052, 853)\n",
      "   Resampling B11 from (527, 427) to (1052, 853)\n",
      "‚úÖ Saved NDVI ‚Üí /home/student/Documents/NMD project/data/processed/ndvi_index.tif\n",
      "‚úÖ Saved EVI ‚Üí /home/student/Documents/NMD project/data/processed/evi_index.tif\n",
      "‚úÖ Saved CHLORO ‚Üí /home/student/Documents/NMD project/data/processed/chloro_index.tif\n",
      "‚úÖ Saved SOILM ‚Üí /home/student/Documents/NMD project/data/processed/soilm_index.tif\n",
      "\n",
      "======================================================================\n",
      "üíæ LOAD PHASE\n",
      "======================================================================\n",
      "\n",
      "üíæ LOAD: Saving results...\n",
      "‚úÖ Summary saved: /home/student/Documents/NMD project/data/processed/etl_summary_20251022_101458.csv\n",
      "\n",
      "üìÅ All processed files in: /home/student/Documents/NMD project/data/processed\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ETL PIPELINE COMPLETED!\n",
      "======================================================================\n",
      "‚úì Sentinel-2 indices: SUCCESS\n",
      "‚úì Temperature data: SKIPPED/FAILED\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = \"/home/student/Documents/NMD project\"\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, \"data/raw\")\n",
    "PROCESSED_DATA_DIR = os.path.join(BASE_DIR, \"data/processed\")\n",
    "AOI_ZIP_PATH = os.path.join(BASE_DIR, \"Shape files_AOI/Abong-Mbang_WH.zip\")\n",
    "\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# --- CDSE Credentials ---\n",
    "CDSE_USERNAME = \"rolandachia7@gmail.com\"\n",
    "CDSE_PASSWORD = \"AChia672083022@\"\n",
    "\n",
    "# --- WEkEO Credentials ---\n",
    "WEKEO_USERNAME = \"achia10\"\n",
    "WEKEO_PASSWORD = \"AChia672083022@\"\n",
    "\n",
    "# Date range for data collection\n",
    "START_DATE = \"2024-01-01T00:00:00Z\"\n",
    "END_DATE = \"2024-12-31T23:59:59Z\"\n",
    "\n",
    "# ============================================================\n",
    "# AUTHENTICATION\n",
    "# ============================================================\n",
    "\n",
    "def get_cdse_token():\n",
    "    \"\"\"Get access token from Copernicus Data Space.\"\"\"\n",
    "    print(\"üîë Authenticating with CDSE...\")\n",
    "    url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
    "    data = {\n",
    "        \"grant_type\": \"password\",\n",
    "        \"username\": CDSE_USERNAME,\n",
    "        \"password\": CDSE_PASSWORD,\n",
    "        \"client_id\": \"cdse-public\"\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(url, data=data, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        token = r.json()[\"access_token\"]\n",
    "        print(\"‚úÖ CDSE authentication successful\")\n",
    "        return token\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è CDSE authentication failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_wekeo_token():\n",
    "    \"\"\"Get access token from WEkEO.\"\"\"\n",
    "    print(\"üîë Authenticating with WEkEO...\")\n",
    "    url = \"https://gateway.prod.wekeo2.eu/hda-broker/gettoken\"\n",
    "    data = {\"username\": WEKEO_USERNAME, \"password\": WEKEO_PASSWORD}\n",
    "    try:\n",
    "        r = requests.post(url, json=data, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        token = r.json()[\"access_token\"]\n",
    "        print(\"‚úÖ WEkEO authentication successful\")\n",
    "        return token\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è WEkEO authentication failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# EXTRACT - AOI\n",
    "# ============================================================\n",
    "\n",
    "def extract_aoi(zip_path):\n",
    "    \"\"\"Extract and load AOI shapefile.\"\"\"\n",
    "    print(\"\\nüì¶ EXTRACT: Loading AOI shapefile...\")\n",
    "    \n",
    "    # Find or extract shapefile\n",
    "    shp_files = []\n",
    "    for root, dirs, files in os.walk(RAW_DATA_DIR):\n",
    "        shp_files.extend([os.path.join(root, f) for f in files if f.endswith(\".shp\")])\n",
    "    \n",
    "    if not shp_files:\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "            z.extractall(RAW_DATA_DIR)\n",
    "        for root, dirs, files in os.walk(RAW_DATA_DIR):\n",
    "            shp_files.extend([os.path.join(root, f) for f in files if f.endswith(\".shp\")])\n",
    "    \n",
    "    if not shp_files:\n",
    "        raise FileNotFoundError(\"No .shp file found!\")\n",
    "    \n",
    "    aoi = gpd.read_file(shp_files[0])\n",
    "    bbox = aoi.to_crs(epsg=4326).total_bounds\n",
    "    print(f\"‚úÖ AOI loaded: {os.path.basename(shp_files[0])}\")\n",
    "    print(f\"   Bounding box: {bbox}\")\n",
    "    return aoi, bbox\n",
    "\n",
    "# ============================================================\n",
    "# EXTRACT - SENTINEL-2 (CDSE)\n",
    "# ============================================================\n",
    "\n",
    "def extract_sentinel2(token, bbox):\n",
    "    \"\"\"Search and download Sentinel-2 data from CDSE.\"\"\"\n",
    "    print(\"\\nüõ∞Ô∏è EXTRACT: Sentinel-2 from CDSE...\")\n",
    "    \n",
    "    url = \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products\"\n",
    "    filter_query = (\n",
    "        f\"Collection/Name eq 'SENTINEL-2' and \"\n",
    "        f\"Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and \"\n",
    "        f\"att/OData.CSC.StringAttribute/Value eq 'S2MSI2A') and \"\n",
    "        f\"OData.CSC.Intersects(area=geography'SRID=4326;POLYGON(({bbox[0]} {bbox[1]},{bbox[2]} {bbox[1]},\"\n",
    "        f\"{bbox[2]} {bbox[3]},{bbox[0]} {bbox[3]},{bbox[0]} {bbox[1]}))') and \"\n",
    "        f\"ContentDate/Start gt {START_DATE} and ContentDate/Start lt {END_DATE}\"\n",
    "    )\n",
    "    \n",
    "    params = {\"$filter\": filter_query, \"$orderby\": \"ContentDate/Start asc\", \"$top\": 1}\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        products = r.json().get(\"value\", [])\n",
    "        \n",
    "        if not products:\n",
    "            print(\"‚ùå No Sentinel-2 products found\")\n",
    "            return None\n",
    "        \n",
    "        product = products[0]\n",
    "        product_id = product[\"Id\"]\n",
    "        product_name = product[\"Name\"]\n",
    "        print(f\"‚úÖ Found: {product_name}\")\n",
    "        \n",
    "        # Download\n",
    "        download_url = f\"https://zipper.dataspace.copernicus.eu/odata/v1/Products({product_id})/$value\"\n",
    "        headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "        \n",
    "        zip_path = os.path.join(RAW_DATA_DIR, f\"{product_name}.zip\")\n",
    "        \n",
    "        # Check if already downloaded\n",
    "        if os.path.exists(zip_path):\n",
    "            print(f\"‚úÖ Product already downloaded\")\n",
    "        else:\n",
    "            print(f\"‚¨áÔ∏è Downloading...\")\n",
    "            with requests.get(download_url, headers=headers, stream=True, timeout=300) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(zip_path, \"wb\") as f:\n",
    "                    for chunk in r.iter_content(8192):\n",
    "                        f.write(chunk)\n",
    "            print(f\"‚úÖ Download complete\")\n",
    "        \n",
    "        # Extract\n",
    "        extract_folder = os.path.join(RAW_DATA_DIR, product_name)\n",
    "        if not os.path.exists(extract_folder):\n",
    "            with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "                z.extractall(extract_folder)\n",
    "            print(f\"‚úÖ Extracted to: {extract_folder}\")\n",
    "        \n",
    "        return extract_folder\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Sentinel-2 extraction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# EXTRACT - TEMPERATURE (WEkEO)\n",
    "# ============================================================\n",
    "\n",
    "def extract_temperature(token, bbox):\n",
    "    \"\"\"Download ERA5 temperature data from WEkEO.\"\"\"\n",
    "    print(\"\\nüå°Ô∏è EXTRACT: Temperature data from WEkEO...\")\n",
    "    \n",
    "    north, south = round(bbox[3], 2), round(bbox[1], 2)\n",
    "    east, west = round(bbox[2], 2), round(bbox[0], 2)\n",
    "    \n",
    "    # Submit job\n",
    "    url = \"https://gateway.prod.wekeo2.eu/hda-broker/api/v1/dataaccess/jobs\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    job_data = {\n",
    "        \"datasetId\": \"EO:ECMWF:DAT:REANALYSIS_ERA5_SINGLE_LEVELS\",\n",
    "        \"stringChoiceValues\": [\n",
    "            {\"name\": \"product_type\", \"value\": [\"reanalysis\"]},\n",
    "            {\"name\": \"variable\", \"value\": [\"2m_temperature\"]},\n",
    "            {\"name\": \"year\", \"value\": [\"2024\"]},\n",
    "            {\"name\": \"month\", \"value\": [\"january\", \"february\"]},  \n",
    "            {\"name\": \"day\", \"value\": [\"01\", \"15\"]},\n",
    "            {\"name\": \"time\", \"value\": [\"12:00\"]},\n",
    "            {\"name\": \"data_format\", \"value\": [\"netcdf\"]},\n",
    "        ],\n",
    "        \"boundingBoxValues\": [{\"name\": \"area\", \"bbox\": [north, west, south, east]}]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        r = requests.post(url, headers=headers, json=job_data, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        job_id = r.json().get(\"jobId\")\n",
    "        \n",
    "        if not job_id:\n",
    "            print(\"‚ö†Ô∏è Failed to submit job\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"‚úÖ Job submitted: {job_id}\")\n",
    "        print(\"‚è≥ Monitoring job (max 10 minutes)...\")\n",
    "        \n",
    "        # Monitor job\n",
    "        status_url = f\"https://gateway.prod.wekeo2.eu/hda-broker/api/v1/dataaccess/jobs/{job_id}\"\n",
    "        start_time = time.time()\n",
    "        max_wait = 600  # 10 minutes\n",
    "        \n",
    "        while (time.time() - start_time) < max_wait:\n",
    "            r = requests.get(status_url, headers=headers, timeout=60)\n",
    "            status = r.json().get(\"status\", \"unknown\")\n",
    "            \n",
    "            if status == \"completed\":\n",
    "                print(\"‚úÖ Job completed!\")\n",
    "                break\n",
    "            elif status == \"failed\":\n",
    "                print(f\"‚ùå Job failed\")\n",
    "                return None\n",
    "            \n",
    "            time.sleep(20)\n",
    "        else:\n",
    "            print(\"‚è∞ Job timeout - continuing with available data\")\n",
    "            return None\n",
    "        \n",
    "        # Download result\n",
    "        result_url = f\"https://gateway.prod.wekeo2.eu/hda-broker/api/v1/dataaccess/jobs/{job_id}/result\"\n",
    "        r = requests.get(result_url, headers=headers, timeout=60)\n",
    "        download_url = r.json().get(\"url\")\n",
    "        \n",
    "        if not download_url:\n",
    "            print(\"‚ö†Ô∏è No download URL available\")\n",
    "            return None\n",
    "        \n",
    "        # Download file\n",
    "        nc_path = os.path.join(RAW_DATA_DIR, \"ERA5_temperature_2024.nc\")\n",
    "        r = requests.get(download_url, stream=True, timeout=300)\n",
    "        with open(nc_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        print(f\"‚úÖ Temperature data downloaded: {nc_path}\")\n",
    "        return nc_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Temperature extraction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# TRANSFORM - SENTINEL-2 INDICES\n",
    "# ============================================================\n",
    "\n",
    "def transform_sentinel2(product_folder, aoi):\n",
    "    \"\"\"Compute vegetation and soil indices from Sentinel-2.\"\"\"\n",
    "    print(\"\\nüîÑ TRANSFORM: Computing Sentinel-2 indices...\")\n",
    "    \n",
    "    # Find band files\n",
    "    band_map = {}\n",
    "    for root, dirs, files in os.walk(product_folder):\n",
    "        for f in files:\n",
    "            fname = f.upper()\n",
    "            if fname.endswith(\"B02.JP2\"): band_map[\"B2\"] = os.path.join(root, f)\n",
    "            if fname.endswith(\"B04.JP2\"): band_map[\"B4\"] = os.path.join(root, f)\n",
    "            if fname.endswith(\"B05.JP2\"): band_map[\"B5\"] = os.path.join(root, f)\n",
    "            if fname.endswith(\"B08.JP2\"): band_map[\"B8\"] = os.path.join(root, f)\n",
    "            if fname.endswith(\"B11.JP2\"): band_map[\"B11\"] = os.path.join(root, f)\n",
    "    \n",
    "    required = [\"B2\", \"B4\", \"B5\", \"B8\", \"B11\"]\n",
    "    if not all(b in band_map for b in required):\n",
    "        print(f\"‚ö†Ô∏è Missing bands\")\n",
    "        return None\n",
    "    \n",
    "    # Use B4 (10m resolution) as reference\n",
    "    with rasterio.open(band_map[\"B4\"]) as ref:\n",
    "        ref_meta = ref.meta.copy()\n",
    "        aoi_proj = aoi.to_crs(ref.crs)\n",
    "        ref_arr, ref_transform = mask(ref, aoi_proj.geometry, crop=True)\n",
    "        ref_shape = ref_arr[0].shape\n",
    "        \n",
    "        out_meta = ref_meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": ref_shape[0],\n",
    "            \"width\": ref_shape[1],\n",
    "            \"transform\": ref_transform,\n",
    "            \"count\": 1,\n",
    "            \"dtype\": rasterio.float32\n",
    "        })\n",
    "    \n",
    "    # Read and clip bands, resampling to reference shape\n",
    "    bands = {}\n",
    "    from rasterio.warp import reproject, Resampling\n",
    "    \n",
    "    for key, path in band_map.items():\n",
    "        with rasterio.open(path) as src:\n",
    "            # Clip to AOI\n",
    "            arr, transform = mask(src, aoi_proj.geometry, crop=True)\n",
    "            \n",
    "            # If shape doesn't match reference, resample\n",
    "            if arr[0].shape != ref_shape:\n",
    "                print(f\"   Resampling {key} from {arr[0].shape} to {ref_shape}\")\n",
    "                resampled = np.empty(ref_shape, dtype=np.float32)\n",
    "                reproject(\n",
    "                    source=arr[0],\n",
    "                    destination=resampled,\n",
    "                    src_transform=transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=ref_transform,\n",
    "                    dst_crs=ref.crs,\n",
    "                    resampling=Resampling.bilinear\n",
    "                )\n",
    "                bands[key] = resampled.astype(float)\n",
    "            else:\n",
    "                bands[key] = arr[0].astype(float)\n",
    "    \n",
    "    # Compute indices\n",
    "    indices = {\n",
    "        \"NDVI\": (bands[\"B8\"] - bands[\"B4\"]) / (bands[\"B8\"] + bands[\"B4\"] + 1e-6),\n",
    "        \"EVI\": 2.5 * (bands[\"B8\"] - bands[\"B4\"]) / (bands[\"B8\"] + 6*bands[\"B4\"] - 7.5*bands[\"B2\"] + 1),\n",
    "        \"CHLORO\": (bands[\"B5\"] / (bands[\"B4\"] + 1e-6)) - 1,\n",
    "        \"SOILM\": (bands[\"B11\"] - bands[\"B8\"]) / (bands[\"B11\"] + bands[\"B8\"] + 1e-6)\n",
    "    }\n",
    "    \n",
    "    # Save indices as GeoTIFFs\n",
    "    for name, arr in indices.items():\n",
    "        out_path = os.path.join(PROCESSED_DATA_DIR, f\"{name.lower()}_index.tif\")\n",
    "        with rasterio.open(out_path, \"w\", **out_meta) as dst:\n",
    "            dst.write(arr.astype(rasterio.float32), 1)\n",
    "        print(f\"‚úÖ Saved {name} ‚Üí {out_path}\")\n",
    "    \n",
    "    return indices\n",
    "\n",
    "# ============================================================\n",
    "# TRANSFORM - TEMPERATURE DATA\n",
    "# ============================================================\n",
    "\n",
    "def transform_temperature(nc_path, aoi):\n",
    "    \"\"\"Process temperature data and compute statistics.\"\"\"\n",
    "    print(\"\\nüîÑ TRANSFORM: Processing temperature data...\")\n",
    "    \n",
    "    try:\n",
    "        ds = xr.open_dataset(nc_path)\n",
    "        \n",
    "        # Get temperature variable (usually t2m)\n",
    "        temp_var = None\n",
    "        for var in ['t2m', '2t', 'temperature_2m']:\n",
    "            if var in ds.variables:\n",
    "                temp_var = var\n",
    "                break\n",
    "        \n",
    "        if not temp_var:\n",
    "            print(f\"‚ö†Ô∏è Temperature variable not found. Available: {list(ds.variables)}\")\n",
    "            return None\n",
    "        \n",
    "        # Extract data\n",
    "        temp_data = ds[temp_var]\n",
    "        \n",
    "        # Convert from Kelvin to Celsius if needed\n",
    "        if temp_data.max() > 200:  # Likely in Kelvin\n",
    "            temp_data = temp_data - 273.15\n",
    "        \n",
    "        # Compute statistics\n",
    "        stats = {\n",
    "            \"mean_temp\": float(temp_data.mean()),\n",
    "            \"min_temp\": float(temp_data.min()),\n",
    "            \"max_temp\": float(temp_data.max()),\n",
    "            \"std_temp\": float(temp_data.std())\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Temperature stats computed:\")\n",
    "        print(f\"   Mean: {stats['mean_temp']:.2f}¬∞C\")\n",
    "        print(f\"   Min: {stats['min_temp']:.2f}¬∞C\")\n",
    "        print(f\"   Max: {stats['max_temp']:.2f}¬∞C\")\n",
    "        \n",
    "        ds.close()\n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Temperature processing failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# LOAD - SAVE RESULTS\n",
    "# ============================================================\n",
    "\n",
    "def load_results(sentinel_indices, temp_stats):\n",
    "    \"\"\"Save all results to CSV summary file.\"\"\"\n",
    "    print(\"\\nüíæ LOAD: Saving results...\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    summary_path = os.path.join(PROCESSED_DATA_DIR, f\"etl_summary_{timestamp}.csv\")\n",
    "    \n",
    "    with open(summary_path, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"metric\", \"value\", \"unit\"])\n",
    "        \n",
    "        # Sentinel-2 indices\n",
    "        if sentinel_indices:\n",
    "            writer.writerow([\"--- SENTINEL-2 INDICES ---\", \"\", \"\"])\n",
    "            for name, arr in sentinel_indices.items():\n",
    "                writer.writerow([f\"{name}_mean\", f\"{np.nanmean(arr):.4f}\", \"index\"])\n",
    "                writer.writerow([f\"{name}_std\", f\"{np.nanstd(arr):.4f}\", \"index\"])\n",
    "        \n",
    "        # Temperature stats\n",
    "        if temp_stats:\n",
    "            writer.writerow([\"--- TEMPERATURE STATS ---\", \"\", \"\"])\n",
    "            for key, val in temp_stats.items():\n",
    "                writer.writerow([key, f\"{val:.2f}\", \"¬∞C\"])\n",
    "    \n",
    "    print(f\"‚úÖ Summary saved: {summary_path}\")\n",
    "    print(f\"\\nüìÅ All processed files in: {PROCESSED_DATA_DIR}\")\n",
    "\n",
    "# ============================================================\n",
    "# MAIN ETL PIPELINE\n",
    "# ============================================================\n",
    "\n",
    "def main_etl():\n",
    "    \"\"\"Execute complete ETL pipeline.\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üöÄ INTEGRATED ETL PIPELINE: CDSE + WEkEO\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Authenticate\n",
    "    cdse_token = get_cdse_token()\n",
    "    wekeo_token = get_wekeo_token()\n",
    "    \n",
    "    if not cdse_token:\n",
    "        print(\"‚ùå CDSE authentication failed - cannot continue\")\n",
    "        return\n",
    "    \n",
    "    # EXTRACT\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üì• EXTRACT PHASE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    aoi, bbox = extract_aoi(AOI_ZIP_PATH)\n",
    "    sentinel_folder = extract_sentinel2(cdse_token, bbox)\n",
    "    \n",
    "    temp_file = None\n",
    "    if wekeo_token:\n",
    "        temp_file = extract_temperature(wekeo_token, bbox)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Skipping temperature data (WEkEO auth failed)\")\n",
    "    \n",
    "    # TRANSFORM\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üîÑ TRANSFORM PHASE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sentinel_indices = None\n",
    "    if sentinel_folder:\n",
    "        sentinel_indices = transform_sentinel2(sentinel_folder, aoi)\n",
    "    \n",
    "    temp_stats = None\n",
    "    if temp_file:\n",
    "        temp_stats = transform_temperature(temp_file, aoi)\n",
    "    \n",
    "    # LOAD\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üíæ LOAD PHASE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    load_results(sentinel_indices, temp_stats)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ ETL PIPELINE COMPLETED!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"‚úì Sentinel-2 indices: {'SUCCESS' if sentinel_indices else 'FAILED'}\")\n",
    "    print(f\"‚úì Temperature data: {'SUCCESS' if temp_stats else 'SKIPPED/FAILED'}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_etl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
